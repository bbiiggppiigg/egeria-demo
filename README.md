# Egeria Artifact 
Source code for the paper, Egeria: A Framework for Automatic Synthesis of HPC Advising Tools through Multi-Layered Natural Language Processing, accepted by SC'17.


The repo contains two main components: Egeria utils and the adiving tools generated by Egeria (cuda, opencl, and openacc). We first focus on the usage of demo systems and then explain how to construct a new advising tool for other HPC documents using Egeria utils. 

# Usage of Demo Systems
The demo shows the advising tools generated from three documentations: _cuda_, _opencl_, and _openacc_. The documentations used are [Cuda Programming Guide](http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html), [OpenCL Optimization Guide](http://developer.amd.com/amd-accelerated-parallel-processing-app-sdk/opencl-optimization-guide/), [OpenACC Programming and Best Practices Guide](http://www.openacc.org/sites/default/files/inline-files/OpenACC_Programming_Guide_0.pdf) respectively. 

## Quick Start
To launch a demo system: 
* Install the following dependencies: Gunicorn 19.6.0, Flask 0.11.1, Textract 1.5.0, Gensim 0.12.4, NLTK 3.2.1, BeautifulSoup 4.4.1
* Setup the host IP address (host) and the port number (port) in _config.py_ and _run.sh_
* Run in the command line (linux only):
```./run.sh```

The demo will automatically create a website with a webpage containing the advising tools generated by Egeria.  [Here](http://152.14.86.153:5000) is a running instance of the demo. For the cuda advising tool, you may try to open and upload a cuda nvvp report (e.g., docs/evaluations/knnjoin.nvvp.report.pdf); the website will return the advising sentences for the program (e.g., docs/evaluations/programs/thread_divergence/knnjoin.cu) with the most relevant ones highlighted. You may also try query "how to improve memory performance" for all three advising tools. 

## Query Tips 
Since the techniques we used are the simple TF-IDF and VSM models. The adivising tools constructed by Egeria are quite sensitive to the the keywords used in the query. The documentations used in the demo usually contain only 100-200 advising sentences. The dictionaries built based on these advising sentences are very likely to miss lots of words. Here are the tips for using the advising tool:

* Various format of the same word will be regarded as one word because we stem each word in an input query before it is used to retrieve sentences.  For example, "warp" and "warps" are regarded as the same in the query. 
* NVVP reports should only be used in the cuda advisor even though advisors based on other documentations can also parse the reports. 
* If the query yields "No Relevant Sentences Found!", then try to change the keywords used in the query. It is very likely that the keywords do not exist in the advising sentences summary. 
* If too few sentences are selected, one can lower the similarity threshold to retrieve more sentences. 
* Either keywords or full sentences can be used as queries. VSM model works the same with a single word query or a query with many words. However, having the same word repeated in the query will increase the importance of that word when retrieving similar sentences. 
* As the dictionary is quite small, similar queries with different keywords might lead to very different responses. One can try to change some keywords in their query. 


# Usage of Egeria
Egeria is a framework for automatic synthesis of advising tools. All the functions used to create an advising tool is in the folder: egeria

To build advising tools for other documents, the main process is as follows:
* Create a new parser file in the folder: ./egeria/parsers/ (e.g. openacc_parser.py). The parser is to extract content from the documentation. 
* Implement the _parse_ function to preprocess the document into a sequence of text blocks. 
	* input: filename 
	* output: a list of dictionary contains the following keys
		* "title": section title for the block,
		* "href": id for the title, used for hyper link. 
		* "body": block content, 
		* "state": natural number used to describe the hierarchical level of the section, start from one. One usually refers to chapters and two refers to section. 
* Enable CoreNLP according to the description on the [official website](https://stanfordnlp.github.io/CoreNLP/corenlp-server.html). 
* (Optional) Custimize the set of keywords in the folder: ./egeria/keywords. 
* Update doc2info dictionary with to-be-processed documentation filename and the weblink. If it is a HTML-based documentation, then customizing _weblink_ could enable the hyperlink to the original documentation.
* Invoke egeria to construct the advising tool through ```python setup.py``` 
* Start the advising tools through ```./run.sh```

The script ```python setup.py```  starts a pipeline to build the advising tool:
1. preprocess the document using the _parse_ function defined in _XXX_parser.py_
2. create _raw.html_ using the entire sentences, recognize advising sentences and use the summary to create _summary.html_. The two HTML files are saved in the _templates_ folder. 
3. build dictionary and TF-IDF models, index the summary, and save them in the _model_ folder

The script ```./run.sh``` starts the flask app defined in _openk.py_ using gunicorn


## check-list ( meta information)
* Algorithm: Semantic Role Labeling (SRL), Dependency Parsing (DP), Word Tokenization, Stemming, Normalization, Term Frequency-Inverse Document Frequency (TF-IDF), Vector Space Model (VSM)
* Program: Python 2.7.10
* Output: suggestions on program optimiztion given a query

## Software depencencies
* Text-related: CoreNLP 3.7.0 (DP), Pycorenlp 0.3.0 (Python interface for CoreNLP), Pracnlptools 1.0 (SENNA), NLTK 3.2.1 (SnowballStemmer, WordNetLemmatizer, sent_tokenize, word_tokenize), Gensim (VSM, TF-IDF), Textract (NVVP report parser), 
* Web-related: Gunicorn (19.6.0), Flask 0.11.1, BeautifulSoup 4.4.1.
 
# Folders
* docs: contains documentations to be processed by egeria to build advising tools. The subfolder _evaluations_ contains sample NVVP reports, ground truth responses/summary, and programs used in the evaluation of the paper.  
* egeria: the Egeria functions used to construct advising tool tools
* logs: query records

* models: tfidf model and the dictionary

* static: static files or scripts used for the webpages
* templates: htmls to be rendered
* uploads: store the uploaded NVVP report
* config.py: configurations including documentation information, similairty score threshold, port and host, etc. 
* openk.py: create a flask app
	
* setup.py: build dictionary and tfidf model
* run.sh: execute Python Setup.py and then run the advising tool

# Contact

email: hguan2 at ncsu.edu
