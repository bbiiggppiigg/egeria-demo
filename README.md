# Egeria artifact 
demo for the paper, Egeria: A Framework for Automatic Synthesis of HPC Advising Tools through Multi-Layered Natural Language Processing, submitted to SC'17.

## Folders
* utils: contains the functions used to construct advising tool tools
* cuda: the cuda advising tool
	* models: tfidf model and the dictionary
	* nvvp-reports: sample NVVP reports, ground truth responses, and programs used in the evaluation.  
	* static: scripts used for the webpages
	* templates: htmls to be rendered
	* uploads: store the uploaded NVVP report
	* Config.py: configurations including keywords, weblink to the documentations, similairty score threshold, port and host, etc. 
	* openk.py: app
	* Parser.py: the parser for the original HTML documentation; specific to the documentation. The output of the parser should be a list of dict with the format:
		* "title": section title for the block,
		* "href": id for the title, 
		* "body": block content, 
		* "state": natural number used to describe the hierarchical level of the section.
	* Setup.py: build dictionary and tfidf model
	* run.sh: run the demo
* opencl: similar structure as cuda
* xeon: similar structure as cuda

## check-list ( meta information)
* Algorithm: Semantic Role Labeling (SRL), Dependency Parsing (DP), Word Tokenization, Stemming, Normalization, Term Frequency-Inverse Document Frequency (TF-IDF), Vector Space Model (VSM)
* Program: Python 2.7.10
* Datasets: [Cuda Programming Guide](http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html), [OpenCL Optimization Guide](http://developer.amd.com/amd-accelerated-parallel-processing-app-sdk/opencl-optimization-guide/), [Xeon Best Practice Guide](http://www.prace-ri.eu/best-practice-guide-intel-xeon-phi-html/)
* Output: suggestions on program optimiztion given a query

## Software depencencies
* Text-related: CoreNLP 3.7.0 (DP), Pycorenlp 0.3.0 (Python interface for CoreNLP), Pracnlptools 1.0 (SENNA), NLTK 3.2.1 (SnowballStemmer, WordNetLemmatizer, sent_tokenize, word_tokenize), Gensim (VSM, TF-IDF), Textract (NVVP report parser), 
* Web-related: Gunicorn (19.6.0), Flask 0.11.1, BeautifulSoup 4.4.1.

## usage
* To launch the demo system: 
	* Install the following dependencies: Gunicorn, Flask, Textract, Gensim, NLTK, BeautifulSoup
	* Open the project folder (e.g. cuda), and run in the command line (linux only):
	```./run.sh```
	The demo will automatically create a website with a webpage presenting the advising sentences generated by the cuda advisor. The default number of worker are 4 and the port number is 5000. These can be changed in the Config.py file. 
	
* To build advising tools for other documents, the process is as follows:
	* Implement the Parser.py: preprocess the documents into a sequence of blocks. 
	* Enable CoreNLP according to the description on the [official website](https://stanfordnlp.github.io/CoreNLP/corenlp-server.html). 
	* (Optional) Custimize the set of keywords and other configurations in Config.py
	* Invoke the advising tools through ```./run.sh```
	
## query tips 
Since the techniques we used are the simple TF-IDF and VSM models. The adivising tools constructed by Egeria are quite sensitive to the the keywords used in the query. The documentations used in the demo usually contain only 100-200 advising sentences. The dictionaries built based on these advising sentences are very likely to miss lots of words. Here are the tips for using the advising tool:

* Various format of the same word will be regarded as one word. For example, "warp" and "warps" are regarded the same in the query. 
* NVVP reports should be used in the cuda advisor even though advisors based on other documentations can also parse the reports. 
* If the query yields "No Relevant Sentences Found!", then try to change the keywords used in the query. It is very likely that the keywords do not exist in the advising sentences summary. 
* If too few sentences are selected, one can lower the similarity threshold to retrieve more sentences. 
* Either keywords or full sentences can be used as queries. As the dictionary is quite small, similar queries with different keywords might lead to very different responses. One can try to change some keywords in their query. 
 

 

